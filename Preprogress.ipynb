{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从文件中读取词数据，并将词数据生成集合返回，可用来读取停用词集合等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_set(words_file_path):\n",
    "    '''\n",
    "    从文件中读取词数据，并将词数据生成集合返回\n",
    "    :words_file_path 保存词数据的文件路径\n",
    "    :return 词集合\n",
    "    '''\n",
    "    words_set = set()\n",
    "    with open(words_file_path, 'r') as fp:\n",
    "        for line in fp.readlines():\n",
    "            word = line.strip().decode(\"utf-8\")\n",
    "            # 去掉重复的词\n",
    "            if len(word)>0 and word not in words_set:\n",
    "                words_set.add(word)\n",
    "    return words_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切词，并以样本格式保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as posseg\n",
    "import os\n",
    "\n",
    "def cut_words(root_path, target_path, stopwords, all_flags):\n",
    "    '''\n",
    "    切词，并以样本格式保存\n",
    "    :root_path 原始文本根目录路径\n",
    "    :target_path 样本文档目标存储路径\n",
    "    :stopwords 停用词集合\n",
    "    :all_flags 允许保留的词性\n",
    "    '''\n",
    "    # 获取所有存储不同类别的新闻文本的目录名称\n",
    "    class_names = os.listdir(root_path)\n",
    "    # 打开样本目标文件，准备写入\n",
    "    with open(target_path, 'w+') as fw:\n",
    "        # 遍历所有存储不同类别的新闻文本的目录名称\n",
    "        for class_name in class_names:\n",
    "            # 拼装所有存储不同类别的新闻文本的目录路径\n",
    "            class_dir_path = root_path + '/' + class_name\n",
    "            # 获取类别目录下全部新闻文件名称\n",
    "            document_names = os.listdir(class_dir_path)\n",
    "            # 遍历全部新闻文件名称\n",
    "            for document_name in document_names:\n",
    "                # 拼装新闻文件路径\n",
    "                document_path = class_dir_path + '/' + document_name\n",
    "                # 打开每个新闻文件，读取内容\n",
    "                with open(document_path, 'r') as fr:\n",
    "                    # 读取新闻文件内容，并去除干扰字符\n",
    "                    document_text = fr.read().strip().decode('utf-8').replace('\\n', ' ').replace('\\t', ' ')\n",
    "                    # 切词\n",
    "                    segs = posseg.cut(document_text)\n",
    "                    # 将符合要求的词写入样本文件\n",
    "                    content = ''\n",
    "                    for word, flag in segs:\n",
    "                        word = word.encode('utf-8').strip()\n",
    "                        if flag in allow_flags and word not in stopwords:\n",
    "                            content += word\n",
    "                            content += ' '\n",
    "                    fw.write(class_name + '\\t' + content + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 原始文本根目录路径\n",
    "root_path = '/home/beanyon/Desktop/preprogress/thucnews/'\n",
    "# root_path = '/home/beanyon/Desktop/naive_bayes_classifier/Database/SogouC/Sample.mini'\n",
    "# 样本文档目标存储路径\n",
    "target_path = '/home/beanyon/Desktop/preprogress/corpus.txt'\n",
    "# 停用词文档路径\n",
    "stopwords_path = '/home/beanyon/Desktop/preprogress/stopwords.txt'\n",
    "# 允许保留的词性\n",
    "allow_flags = ('v', 'n', 'a', 'ag', 'g', 'vg', 'ng', 'nr', 'ns', 'nt', 'nz', 'i')\n",
    "# 读取停用词集合\n",
    "stopwords = make_word_set(stopwords_path)\n",
    "# 切词\n",
    "cut_words(root_path, target_path, stopwords, allow_flags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
